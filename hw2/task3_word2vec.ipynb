{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "task3_word2vec.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etomoscow/DL-in-NLP/blob/master/hw2/task3_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byoUIGO366r5",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 1.3: Naive word2vec (40 points)\n",
        "\n",
        "This task can be formulated very simply. Follow this [paper](https://arxiv.org/pdf/1411.2738.pdf) and implement word2vec like a two-layer neural network with matrices $W$ and $W'$. One matrix projects words to low-dimensional 'hidden' space and the other - back to high-dimensional vocabulary space.\n",
        "\n",
        "![word2vec](https://i.stack.imgur.com/6eVXZ.jpg)\n",
        "\n",
        "You can use TensorFlow/PyTorch and code from your previous task.\n",
        "\n",
        "## Results of this task: (30 points)\n",
        " * trained word vectors (mention somewhere, how long it took to train)\n",
        " * plotted loss (so we can see that it has converged)\n",
        " * function to map token to corresponding word vector\n",
        " * beautiful visualizations (PCE, T-SNE), you can use TensorBoard and play with your vectors in 3D (don't forget to add screenshots to the task)\n",
        "\n",
        "## Extra questions: (10 points)\n",
        " * Intrinsic evaluation: you can find datasets [here](http://download.tensorflow.org/data/questions-words.txt)\n",
        " * Extrinsic evaluation: you can use [these](https://medium.com/@dataturks/rare-text-classification-open-datasets-9d340c8c508e)\n",
        "\n",
        "Also, you can find any other datasets for quantitative evaluation.\n",
        "\n",
        "Again. It is **highly recommended** to read this [paper](https://arxiv.org/pdf/1411.2738.pdf)\n",
        "\n",
        "Example of visualization in tensorboard:\n",
        "https://projector.tensorflow.org\n",
        "\n",
        "Example of 2D visualisation:\n",
        "\n",
        "![2dword2vec](https://www.tensorflow.org/images/tsne.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15_-PAQp6-Ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random, torch, collections\n",
        "import torch.nn as nn\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFzdpqxV9gEM",
        "colab_type": "code",
        "outputId": "ab01db6c-b243-44fe-c834-0b38f2ba5c7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "!wget http://mattmahoney.net/dc/text8.zip\n",
        "!unzip text8.zip\n",
        "with open('text8') as text_file:\n",
        "    corpus = text_file.read().split()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-22 07:14:01--  http://mattmahoney.net/dc/text8.zip\n",
            "Resolving mattmahoney.net (mattmahoney.net)... 67.195.197.75\n",
            "Connecting to mattmahoney.net (mattmahoney.net)|67.195.197.75|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31344016 (30M) [application/zip]\n",
            "Saving to: ‘text8.zip’\n",
            "\n",
            "text8.zip           100%[===================>]  29.89M   727KB/s    in 43s     \n",
            "\n",
            "2020-02-22 07:14:45 (712 KB/s) - ‘text8.zip’ saved [31344016/31344016]\n",
            "\n",
            "Archive:  text8.zip\n",
            "  inflating: text8                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnEyjS3Y9lMH",
        "colab_type": "code",
        "outputId": "8f752eec-0d27-4d38-8413-9f102cbd0f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "pprint(' '.join(word for word in corpus[:100]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('anarchism originated as a term of abuse first used against early working '\n",
            " 'class radicals including the diggers of the english revolution and the sans '\n",
            " 'culottes of the french revolution whilst the term is still used in a '\n",
            " 'pejorative way to describe any act that used violent means to destroy the '\n",
            " 'organization of society it has also been taken up as a positive label by '\n",
            " 'self defined anarchists the word anarchism is derived from the greek without '\n",
            " 'archons ruler chief king anarchism as a political philosophy is the belief '\n",
            " 'that rulers are unnecessary and should be abolished although there are '\n",
            " 'differing')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCCulQz_9oUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCABULARY_SIZE = 10000\n",
        "UNK = '<UNK>'\n",
        "\n",
        "def create_dataset(corpus, vocab_size=VOCABULARY_SIZE, unk_token=UNK):\n",
        "    dataset = []\n",
        "    counter_dict = collections.Counter(corpus)\n",
        "    vocab = counter_dict.most_common(VOCABULARY_SIZE)\n",
        "    words = [x[0] for x in vocab]\n",
        "    words.append(unk_token)\n",
        "    min_allowed_freq = vocab[-1][1]\n",
        "    #use only high-frequency words\n",
        "    #change all other words to UNK\n",
        "    for _, word in enumerate(corpus):\n",
        "        if counter_dict[word] > min_allowed_freq:\n",
        "            dataset.append(word)\n",
        "        else:\n",
        "            dataset.append(unk_token)\n",
        "        \n",
        "    word2idx = {word: idx for (idx, word) in enumerate(words)}\n",
        "    idx2word = {idx: word for (idx, word) in enumerate(words)}\n",
        "    return dataset, word2idx, idx2word, len(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1w-WPl29zp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data, word2idx, idx2word, vocab_size = create_dataset(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C2UyGYV93QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Batcher(object):\n",
        "    def __init__(self,dataset, window_size, batch_size, word2idx, idx2word):\n",
        "        self.dataset = dataset\n",
        "        self.window_size = window_size\n",
        "        self.batch_size = batch_size\n",
        "        self.word2idx = word2idx\n",
        "        self.idx2word = idx2word\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        global index\n",
        "        batch = []\n",
        "        labels = []\n",
        "        dataset = self.dataset \n",
        "        window_size = self.window_size\n",
        "        batch_size = self.batch_size\n",
        "        word2idx = self.word2idx\n",
        "        idx2word = self.idx2word\n",
        "        \n",
        "        for _ in range(batch_size):\n",
        "            # create a batch only if have at least\n",
        "            #n words to the left and n words to the right\n",
        "            #where n is window size\n",
        "            if (index - window_size < 0) or (index + window_size > len(dataset)-1):\n",
        "                #we need to increment index through epochs of learning\n",
        "                index = (index + 1) % len(dataset)\n",
        "            #now create context and batch\n",
        "            else:\n",
        "                #add word \n",
        "                batch.append(word2idx[dataset[index]])\n",
        "                \n",
        "                labels_batch = []\n",
        "                sliding_window = dataset[index-window_size:index] + dataset[index+1: index+window_size+1]\n",
        "                for word in sliding_window:\n",
        "                    labels_batch.append(word2idx[word])\n",
        "                labels.append(labels_batch)\n",
        "                #again update index\n",
        "                index = (index + 1) % len(dataset)\n",
        "        \n",
        "        return (batch, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMPOBBGP9kq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Word2Vec(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, emb_size, hidden_size=128, window_size=window_size):\n",
        "        super(Word2Vec, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.emb_size = emb_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.window_size = window_size\n",
        "\n",
        "        #declaring the structure of nn \n",
        "        self.dropout = nn.Dropout(p=0.1) #not sure we need this in vanilla version\n",
        "        self.embed = nn.Embedding(input_size, emb_size)\n",
        "        self.linear_1 = nn.Linear(emb_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, 2*window_size*vocab_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embs = self.embed(input)\n",
        "        embs = embs.squeeze() #get the proper shapes\n",
        "        output = self.dropout(self.linear_1(F.relu(embs)))\n",
        "        output = self.dropout(self.linear_2(F.relu(output)))\n",
        "        log_proba = self.softmax(output)\n",
        "        return log_proba"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaK7II8XHuvv",
        "colab_type": "code",
        "outputId": "249e7729-636b-4f91-dc28-0b97095e0e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "USE_GPU = True\n",
        "\n",
        "dtype = torch.float32 \n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print('using device:', device)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gve_hJxmRtTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 12\n",
        "emb_size = 20\n",
        "window_size = 6\n",
        "print_every = 100\n",
        "input_size = vocab_size\n",
        "\n",
        "#let's train \n",
        "model = Word2Vec(input_size, emb_size)\n",
        "model = model.to(device=device)\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.008, momentum=0.9)\n",
        "\n",
        "index = 0 #zero index for batcher\n",
        "batcher = Batcher(dataset=data, batch_size=batch_size, window_size=window_size, word2idx=word2idx, idx2word=idx2word)\n",
        "build_batch = iter(batcher)\n",
        "\n",
        "losses = []\n",
        "num_iters = len(data) // batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K9PC1LhS6V2",
        "colab_type": "code",
        "outputId": "8eb1f10a-e32c-4fc1-9567-7d33cca44867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "for e in range(1000):\n",
        "    batch, label = next(build_batch)\n",
        "    #print(batch, label)\n",
        "    model.train() \n",
        "    batch = torch.tensor(batch).type(torch.LongTensor).to(device=device)\n",
        "    label = torch.tensor(label).type(torch.LongTensor).to(device=device)\n",
        "    print(batch.shape)\n",
        "    scores = model(batch).to(device=device)\n",
        "    print(scores.shape)\n",
        "    loss = loss_function(scores, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses.append(loss.item())\n",
        "    if e % it_per_ep == 0:\n",
        "        print('Iteration %d, loss = %.4lg' % (e, sum(losses[-it_per_ep:])))\n",
        "        print('Time %lg' % (time.clock() - start_time))\n",
        "        print()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6])\n",
            "torch.Size([6, 60006])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-47c216aad330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qst6uy68TCyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}