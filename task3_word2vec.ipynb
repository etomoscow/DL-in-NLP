{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "task3_word2vec.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byoUIGO366r5",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 1.3: Naive word2vec (40 points)\n",
        "\n",
        "This task can be formulated very simply. Follow this [paper](https://arxiv.org/pdf/1411.2738.pdf) and implement word2vec like a two-layer neural network with matrices $W$ and $W'$. One matrix projects words to low-dimensional 'hidden' space and the other - back to high-dimensional vocabulary space.\n",
        "\n",
        "![word2vec](https://i.stack.imgur.com/6eVXZ.jpg)\n",
        "\n",
        "You can use TensorFlow/PyTorch and code from your previous task.\n",
        "\n",
        "## Results of this task: (30 points)\n",
        " * trained word vectors (mention somewhere, how long it took to train)\n",
        " * plotted loss (so we can see that it has converged)\n",
        " * function to map token to corresponding word vector\n",
        " * beautiful visualizations (PCE, T-SNE), you can use TensorBoard and play with your vectors in 3D (don't forget to add screenshots to the task)\n",
        "\n",
        "## Extra questions: (10 points)\n",
        " * Intrinsic evaluation: you can find datasets [here](http://download.tensorflow.org/data/questions-words.txt)\n",
        " * Extrinsic evaluation: you can use [these](https://medium.com/@dataturks/rare-text-classification-open-datasets-9d340c8c508e)\n",
        "\n",
        "Also, you can find any other datasets for quantitative evaluation.\n",
        "\n",
        "Again. It is **highly recommended** to read this [paper](https://arxiv.org/pdf/1411.2738.pdf)\n",
        "\n",
        "Example of visualization in tensorboard:\n",
        "https://projector.tensorflow.org\n",
        "\n",
        "Example of 2D visualisation:\n",
        "\n",
        "![2dword2vec](https://www.tensorflow.org/images/tsne.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15_-PAQp6-Ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random, torch, collections\n",
        "import torch.nn as nn\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFzdpqxV9gEM",
        "colab_type": "code",
        "outputId": "2c830696-4bde-4214-a2ef-16f8dbebad93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget http://mattmahoney.net/dc/text8.zip\n",
        "!unzip text8.zip\n",
        "with open('text8') as text_file:\n",
        "    corpus = text_file.read().split()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-20 14:58:00--  http://mattmahoney.net/dc/text8.zip\n",
            "Resolving mattmahoney.net (mattmahoney.net)... 67.195.197.75\n",
            "Connecting to mattmahoney.net (mattmahoney.net)|67.195.197.75|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31344016 (30M) [application/zip]\n",
            "Saving to: ‘text8.zip.1’\n",
            "\n",
            "text8.zip.1         100%[===================>]  29.89M  2.03MB/s    in 15s     \n",
            "\n",
            "2020-02-20 14:58:15 (2.00 MB/s) - ‘text8.zip.1’ saved [31344016/31344016]\n",
            "\n",
            "Archive:  text8.zip\n",
            "replace text8? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnEyjS3Y9lMH",
        "colab_type": "code",
        "outputId": "4763fb31-c37b-48a0-a11d-00d7e9169770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "pprint(' '.join(word for word in corpus[:100]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('anarchism originated as a term of abuse first used against early working '\n",
            " 'class radicals including the diggers of the english revolution and the sans '\n",
            " 'culottes of the french revolution whilst the term is still used in a '\n",
            " 'pejorative way to describe any act that used violent means to destroy the '\n",
            " 'organization of society it has also been taken up as a positive label by '\n",
            " 'self defined anarchists the word anarchism is derived from the greek without '\n",
            " 'archons ruler chief king anarchism as a political philosophy is the belief '\n",
            " 'that rulers are unnecessary and should be abolished although there are '\n",
            " 'differing')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCCulQz_9oUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCABULARY_SIZE = 10000\n",
        "UNK = '<UNK>'\n",
        "\n",
        "def create_dataset(corpus, vocab_size=VOCABULARY_SIZE, unk_token=UNK):\n",
        "    dataset = []\n",
        "    counter_dict = collections.Counter(corpus)\n",
        "    vocab = counter_dict.most_common(VOCABULARY_SIZE)\n",
        "    words = [x[0] for x in vocab]\n",
        "    words.append(unk_token)\n",
        "    min_allowed_freq = vocab[-1][1]\n",
        "    #use only high-frequency words\n",
        "    #change all other words to UNK\n",
        "    for _, word in enumerate(corpus):\n",
        "        if counter_dict[word] > min_allowed_freq:\n",
        "            dataset.append(word)\n",
        "        else:\n",
        "            dataset.append(unk_token)\n",
        "        \n",
        "    word2idx = {word: idx for (idx, word) in enumerate(words)}\n",
        "    idx2word = {idx: word for (idx, word) in enumerate(words)}\n",
        "    return dataset, word2idx, idx2word, len(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1w-WPl29zp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data, word2idx, idx2word, vocab_size = create_dataset(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C2UyGYV93QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Batcher(object):\n",
        "    def __init__(self,dataset, window_size, batch_size, word2idx, idx2word):\n",
        "        self.dataset = dataset\n",
        "        self.window_size = window_size\n",
        "        self.batch_size = batch_size\n",
        "        self.word2idx = word2idx\n",
        "        self.idx2word = idx2word\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        global index\n",
        "        batch = []\n",
        "        labels = []\n",
        "        dataset = self.dataset \n",
        "        window_size = self.window_size\n",
        "        batch_size = self.batch_size\n",
        "        word2idx = self.word2idx\n",
        "        idx2word = self.idx2word\n",
        "        \n",
        "        for _ in range(batch_size):\n",
        "            # create a batch only if have at least\n",
        "            #n words to the left and n words to the right\n",
        "            #where n is window size\n",
        "            if (index - window_size < 0) or (index + window_size > len(dataset)-1):\n",
        "                #we need to increment index through epochs of learning\n",
        "                index = (index + 1) % len(dataset)\n",
        "            #now create context and batch\n",
        "            else:\n",
        "                #add word \n",
        "                batch.append(word2idx[dataset[index]])\n",
        "                \n",
        "                labels_batch = []\n",
        "                sliding_window = dataset[index-window_size:index] + dataset[index+1: index+window_size+1]\n",
        "                for word in sliding_window:\n",
        "                    labels_batch.append(word2idx[word])\n",
        "                labels.append(labels_batch)\n",
        "                #again update index\n",
        "                index = (index + 1) % len(dataset)\n",
        "        \n",
        "        return (batch, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWarFENC-INj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehot(batch, batch_size, voc_size):\n",
        "    if batch_size > 1:\n",
        "        batch_onehot = torch.zeros((batch_size, voc_size))\n",
        "        for x, y in enumerate(batch):\n",
        "            for i in y:\n",
        "                i = int(i)\n",
        "                batch_onehot[x, i] = batch_onehot[x, i] + 1\n",
        "    else:\n",
        "        batch_onehot = torch.zeros((voc_size))\n",
        "        for x in batch:\n",
        "            x = int(x)\n",
        "            batch_onehot[x] = 1\n",
        "    return batch_onehot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMPOBBGP9kq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Word2Vec(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Word2Vec, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.linear_1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.linear_1(input)\n",
        "        output = F.log_softmax(self.linear_2(output), dim=1)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaK7II8XHuvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ca55546-f826-45b1-bc02-f0dde3b47f41"
      },
      "source": [
        "import time\n",
        "part_data = data[:300000]\n",
        "input_size = vocab_size \n",
        "batch_size = 1000\n",
        "hidden_size = 20\n",
        "window_size = 2\n",
        "print_every = 100\n",
        "\n",
        "USE_GPU = True\n",
        "\n",
        "dtype = torch.float32 \n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print('using device:', device)\n",
        "\n",
        "model = Word2Vec(input_size=vocab_size, hidden_size=hidden_size)\n",
        "model = model.to(device=device)\n",
        "index = 0\n",
        "batcher = Batcher(dataset=part_data, window_size=window_size, batch_size=batch_size, word2idx=word2idx, idx2word=idx2word)\n",
        "build_batch = iter(batcher)\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "\n",
        "losses = []\n",
        "it_per_ep = len(part_data) // batch_size"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TKDJjOuGzTe",
        "colab_type": "code",
        "outputId": "5ae7ca53-ade5-4523-d636-a7516fd834c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "start_time = time.clock()\n",
        "for e in range(30000):\n",
        "    batch, label = next(build_batch)\n",
        "    one_hot_vector = onehot(batch=batch, batch_size=batch_size, voc_size=vocab_size)\n",
        "    model.train() \n",
        "    x = onehot.to(device=device, dtype=dtype) / window_size \n",
        "    scores = model(x).to(device=device, dtype=dtype)\n",
        "    loss = loss_function(scores, torch.tensor(label, device=device, dtype=torch.long))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses.append(loss.item())\n",
        "    if e % it_per_ep == 0:\n",
        "        print('Iteration %d, loss = %.4lg' % (e, sum(losses[-it_per_ep:])))\n",
        "        print('Time %lg' % (time.clock() - start_time))\n",
        "        print()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-eae86afd93d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mone_hot_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-8afca03aeca8>\u001b[0m in \u001b[0;36monehot\u001b[0;34m(batch, batch_size, voc_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mbatch_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mbatch_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynaTLX69N9tU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9baa71ba-c161-4078-e12d-475b5769079e"
      },
      "source": [
        "for x,y in enumerate(batch):\n",
        "    print(x,y)\n",
        "    break"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 406\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}